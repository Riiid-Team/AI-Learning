{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import acquire\n",
    "\n",
    "import random\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in primary dataset.\n",
    "df = pd.read_csv('train.csv', usecols=[1,2,3,4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training dataset\n",
    "To reduce the memory size of our training data, we selected a random sample of 100,000 students from `train.csv`.\n",
    "1. Select 100,000 user ids from `train.csv` to use as our train dataset.\n",
    "2. Cast numeric column data types using an appropriate precision to reduce memory size.\n",
    "\n",
    "## Sample training data\n",
    "- Selecting 100_000 users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all users with more than 10 rows.\n",
    "user_ids = df['user_id'].value_counts()[df['user_id'].value_counts() > 10].index.to_list()\n",
    "\n",
    "# Select a random sample of 100_000 user_ids.\n",
    "sampled_ids = random.sample(user_ids, 100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sampled_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampled_users(df):\n",
    "    '''\n",
    "    This function accepts data from `train.csv` and\n",
    "    returns a random sample of 100_000 user_ids.\n",
    "    '''\n",
    "    user_ids = df['user_id'].value_counts()[df['user_id'].value_counts() > 10].index.to_list()\n",
    "    sampled_ids = random.sample(user_ids, 100_000)\n",
    "    return sampled_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the selected user_ids, filter the dataset for the first 100_000.\n",
    "filtered_data = pd.DataFrame()\n",
    "\n",
    "data = df.loc[df['user_id'].isin(sampled_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 100_000 users!!!!\n",
    "data.user_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache local file for next steps.\n",
    "# data.to_csv('sampled_train.csv', index=False)\n",
    "\n",
    "# Dataset loads correctly.\n",
    "# df = pd.read_csv('sampled_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Casting data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datatype_converter():\n",
    "    '''\n",
    "    This function returns a dictionary of column names and data types to convert.\n",
    "    '''\n",
    "    \n",
    "    train_data_types_dict = {\n",
    "    'timestamp': np.int64,\n",
    "    'user_id': np.int32,\n",
    "    'content_id': np.int16,\n",
    "    'content_type_id': np.int16,\n",
    "    'task_container_id' : np.int16,\n",
    "    'user_answer' : np.int8,\n",
    "    'answered_correctly': np.int8,\n",
    "    'prior_question_elapsed_time': np.float16\n",
    "    }\n",
    "    \n",
    "    lectures_data_types_dict = {\n",
    "    'lecture_id' : np.int16,\n",
    "    'tag' : np.int8,\n",
    "    'part' : np.int8\n",
    "    }\n",
    "\n",
    "    questions_data_types_dict = {\n",
    "    'question_id' : np.int16,\n",
    "    'bundle_id' : np.int16,\n",
    "    'part' : np.int8\n",
    "    }\n",
    "    \n",
    "    \n",
    "    return train_data_types_dict, lectures_data_types_dict, questions_data_types_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampled_train():\n",
    "    '''\n",
    "    This function selects a random sample of 100_000 users from the `train.csv` dataset.\n",
    "    Returns a dataframe of 100_000 users that have more than 10 rows of data.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    None\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data : pandas.core.frame.DataFrame\n",
    "        A pandas dataframe of 100,000 randomly selected\n",
    "        users.\n",
    "    '''\n",
    "    train_dtypes, _, _ = datatype_converter()\n",
    "    \n",
    "    if os.path.isfile('sampled_train.csv'):\n",
    "        return pd.read_csv('sampled_train.csv',\n",
    "                           index_col=False,\n",
    "                           dtype=train_dtypes)\n",
    "    else:\n",
    "        \n",
    "    # Read in `train.csv` data\n",
    "        df = pd.read_csv('train.csv', dtype=train_dtypes, usecols=[1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "        sampled_ids = sampled_users(df)\n",
    "\n",
    "        sampled_data = df.loc[df['user_id'].isin(sampled_ids)]\n",
    "\n",
    "        # Cache local file of sampled data.\n",
    "        sampled_data.to_csv('sampled_train.csv', index=False)\n",
    "    \n",
    "    # Return the dataframe\n",
    "    return sampled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to reproduce the modified training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function.\n",
    "df = sampled_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It works.\n",
    "df.user_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check our data types and memory usage.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge datasets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, lecture_dtypes, question_dtypes = datatype_converter()\n",
    "\n",
    "df_lectures = pd.read_csv('lectures.csv', dtype=lecture_dtypes)\n",
    "df_questions = pd.read_csv('questions.csv', dtype=question_dtypes)\n",
    "\n",
    "# Left join df_train and df_lectures using `content_id` as the primary key.\n",
    "df_merged = df.merge(df_lectures, left_on='content_id', right_on='lecture_id', how='left')\n",
    "\n",
    "# Left join df_merged and df_questions using `content_id` as the primary key.\n",
    "df_data = df_merged.merge(df_questions, left_on='content_id', right_on='question_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_riiid_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame()\n",
    "validate = pd.DataFrame()\n",
    "test = pd.DataFrame()\n",
    "\n",
    "# Set up the train size\n",
    "train_size = 0.8\n",
    "validate_size = 0.1\n",
    "\n",
    "sampled_ids = df.user_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in sampled_ids:\n",
    "    data = df.loc[df['user_id'] == user]\n",
    "    n = data.shape[0]\n",
    "\n",
    "    train_end_index = int(train_size * n)\n",
    "    validate_end_index = train_end_index + int(validate_size * n)\n",
    "\n",
    "    df_train = data.iloc[:train_end_index]\n",
    "    df_validate = data.iloc[train_end_index:validate_end_index]\n",
    "    df_test = data.iloc[validate_end_index:]\n",
    "\n",
    "    train = pd.concat([train, df_train])\n",
    "    validate = pd.concat([validate, df_validate])\n",
    "    test = pd.concat([test, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print the shape of the original, train and test\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('sampled_trainset.csv', index=False)\n",
    "validate.to_csv('validate.csv', index=False)\n",
    "test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a function to split data using Quasi-GroupKFold method\n",
    "The way our data is currently split for MVP:\n",
    "- 100,000 randomly selected users that have more that 10 interactions with Riiid's Knowledge tracing application.\n",
    "- Each user has _sequential_ data, indicated by the variable `timestamp`.\n",
    "- Data is split using a percentage-based method.\n",
    "- 0% - 80% of a users data is the training set.\n",
    "- 80% - 90% of a users data is in the validation set.\n",
    "- 90% - 100% of a users data is in the test set.\n",
    "\n",
    "The way we split the data is important. As we currently have our splits, several issues arise that impact our data exploration and modeling performance.\n",
    "- Spliting the data using a percentage-based method removes questions and lectures from our training data. If a model encounters a question it has never seen before, how can it accurately model reality? We need to have all questions appear at least once in our dataset.\n",
    "    - If this was _purely_ a time series problem, that would be fine.\n",
    "- The training set uses 80% of a users data, this impacts our statistical analysis. If we have _all_ of a users data, we can correctly calculate population statistics from a _sample_ of users. We can then compare statistics on a user/grouped level with the population.\n",
    "\n",
    "What is the solution?\n",
    "\n",
    "> <strong>Splitting by users!</strong>\n",
    "\n",
    "## Splitting by users\n",
    "How does this solve our exploration and modeling issues?\n",
    "> <strong>By creating users the model has never seen before!</strong>\n",
    "\n",
    "This simulates _new_ users interacting with Riiid's Knowledge Tracing Application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = acquire.get_riiid_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.lecture_id = df_data.lecture_id.astype('Int16')\n",
    "df_data.tag = df_data.tag.astype('Int8')\n",
    "df_data.part_x = df_data.part_x.astype('Int8')\n",
    "df_data.part_y = df_data.part_y.astype('Int8')\n",
    "df_data.question_id = df_data.question_id.astype('Int16')\n",
    "df_data.bundle_id = df_data.bundle_id.astype('Int16')\n",
    "df_data.lecture_id = df_data.lecture_id.astype('Int32')\n",
    "\n",
    "# Prefix part names with the originating dataframe name.\n",
    "df_data.rename(columns={'part_x': 'lecture_part',\n",
    "                        'part_y': 'question_part'},\n",
    "                   inplace=True)\n",
    "\n",
    "# Cache the data.\n",
    "df_data.to_csv('riiid_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many users are in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = df_data.user_id.unique()\n",
    "print(f'There are {len(users):,} users.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new data splits using percentage of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentages of orginal dataset\n",
    "train_size = .8\n",
    "validate_size = .1\n",
    "test_size = .1\n",
    "\n",
    "# Calculate the number of users in each dataset.\n",
    "train_users = int(len(users)*train_size)\n",
    "validate_users = math.ceil(len(users)*validate_size)\n",
    "test_users = math.ceil(len(users)*test_size)\n",
    "\n",
    "# Display the results.\n",
    "print(f'Train set would contain {train_users:,} users')\n",
    "print(f'Validate set would contain {validate_users:,} users')\n",
    "print(f'Test set would contain {test_users:,} users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for even splits\n",
    "print(len(users) == sum([train_users, validate_users, test_users]))\n",
    "\n",
    "print(len(users))\n",
    "print(sum([train_users, validate_users, test_users]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test a method to split users into seperate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a random seed to reproduce splits\n",
    "random.seed(123)\n",
    "\n",
    "# Toy example\n",
    "all_users = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Randomly select train set users\n",
    "t_ids = random.sample(all_users, 3)\n",
    "\n",
    "# Remove users assigned to the training set.\n",
    "list(set(all_users) - set(t_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function to reproduce data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_users(df, train_size=.8, validate_size=.1, test_size=.1):\n",
    "    '''\n",
    "    This function accepts the merged dataframe from acquire.get_riiid_data()\n",
    "    and returns train, validate and test sets.\n",
    "    '''\n",
    "    # Set a random seed to reproduce splits\n",
    "    random.seed(123)\n",
    "    \n",
    "    # Gather all user ids\n",
    "    user_ids = list(df['user_id'].unique())\n",
    "    total_num = len(user_ids)\n",
    "    \n",
    "    # Calculate the number of users in train, validate, and test.\n",
    "    train_num = int(total_num*train_size)\n",
    "    validate_num = math.ceil(total_num*validate_size)\n",
    "    test_num = math.ceil(total_num*test_size)\n",
    "    \n",
    "    # Randomly select 80% of the users to be in train.\n",
    "    train_ids = random.sample(user_ids, train_num)\n",
    "    \n",
    "    # Remove user_ids assigned to the training set.\n",
    "    remaining_val_test_users = list(set(user_ids) - set(train_ids))\n",
    "    \n",
    "    # Assign the remaining user ids to validate and test.\n",
    "    validate_ids = random.sample(remaining_val_test_users, validate_num)\n",
    "    test_ids = list(set(remaining_val_test_users) - set(validate_ids))\n",
    "    \n",
    "    # Return the users assigned to train, validate, and test\n",
    "    return train_ids, validate_ids, test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_ids, validate_ids, test_ids = split_users(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_data.loc[df_data['user_id'].isin(train_ids)]\n",
    "validate = df_data.loc[df_data['user_id'].isin(validate_ids)]\n",
    "test = df_data.loc[df_data['user_id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_k.csv', index=False)\n",
    "validate.to_csv('validate_k.csv', index=False)\n",
    "test.to_csv('test_k.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the function to use a subset of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_users(df, train_size=.8, validate_size=.1, test_size=.1, sample=True):\n",
    "    '''\n",
    "    This function accepts the merged dataframe from acquire.get_riiid_data()\n",
    "    and returns train, validate and test sets.\n",
    "    '''\n",
    "    # Set a random seed to reproduce splits\n",
    "    random.seed(123)\n",
    "    \n",
    "    if sample == True:\n",
    "        # Gather a random sample of 100_000 user ids\n",
    "        user_ids = random.sample(list(df['user_id'].unique()), 100_000)\n",
    "    else:\n",
    "        # Gather all user ids\n",
    "        user_ids = list(df['user_id'].unique())\n",
    "    \n",
    "    # Calculate the number of users\n",
    "    total_num = len(user_ids)\n",
    "    \n",
    "    # Calculate the number of users in train, validate. Remaining users go in test\n",
    "    train_num = int(total_num*train_size)\n",
    "    validate_num = math.ceil(total_num*validate_size)\n",
    "    \n",
    "    # Randomly select 80% of the users to be in train.\n",
    "    train_ids = random.sample(user_ids, train_num)\n",
    "    \n",
    "    # Remove user_ids assigned to the training set.\n",
    "    remaining_val_test_users = list(set(user_ids) - set(train_ids))\n",
    "    \n",
    "    # Assign the remaining user ids to validate and test.\n",
    "    validate_ids = random.sample(remaining_val_test_users, validate_num)\n",
    "    test_ids = list(set(remaining_val_test_users) - set(validate_ids))\n",
    "    \n",
    "    # Return the users assigned to train, validate, and test\n",
    "    return train_ids, validate_ids, test_ids\n",
    "\n",
    "\n",
    "def train_validate_test(df, sampled=True):\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    train_ids, validate_ids, test_ids = split_users(df, sample=sampled)\n",
    "\n",
    "    train = df.loc[df['user_id'].isin(train_ids)]\n",
    "    validate = df.loc[df['user_id'].isin(validate_ids)]\n",
    "    test = df.loc[df['user_id'].isin(test_ids)]\n",
    "\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = train_validate_test(acquire.get_riiid_data())\n",
    "train.to_csv('mvp_train.csv', index=False)\n",
    "validate.to_csv('mvp_validate.csv', index=False)\n",
    "test.to_csv('mvp_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the function to use a subset of the data: Sample of 50K users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_users(df, train_size=.8, validate_size=.1, sample=True):\n",
    "    '''\n",
    "    This function accepts the merged dataframe from acquire.get_riiid_data()\n",
    "    and returns train, validate and test sets.\n",
    "    '''\n",
    "    # Set a random seed to reproduce splits\n",
    "    random.seed(123)\n",
    "    \n",
    "    if sample == True:\n",
    "        # Gather a random sample of 50_000 user ids\n",
    "        user_ids = random.sample(list(df['user_id'].unique()), 50_000)\n",
    "    else:\n",
    "        # Gather all user ids\n",
    "        user_ids = list(df['user_id'].unique())\n",
    "    \n",
    "    # Calculate the number of users\n",
    "    total_num = len(user_ids)\n",
    "    \n",
    "    # Calculate the number of users in train, validate. Remaining users go in test\n",
    "    train_num = int(total_num*train_size)\n",
    "    validate_num = math.ceil(total_num*validate_size)\n",
    "    \n",
    "    # Randomly select 80% of the users to be in train.\n",
    "    train_ids = random.sample(user_ids, train_num)\n",
    "    \n",
    "    # Remove user_ids assigned to the training set.\n",
    "    remaining_val_test_users = list(set(user_ids) - set(train_ids))\n",
    "    \n",
    "    # Assign the remaining user ids to validate and test.\n",
    "    validate_ids = random.sample(remaining_val_test_users, validate_num)\n",
    "    test_ids = list(set(remaining_val_test_users) - set(validate_ids))\n",
    "    \n",
    "    # Return the users assigned to train, validate, and test\n",
    "    return train_ids, validate_ids, test_ids\n",
    "\n",
    "\n",
    "def train_validate_test(df, sampled=True):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    train_ids, validate_ids, test_ids = split_users(df, sample=sampled)\n",
    "\n",
    "    train = df.loc[df['user_id'].isin(train_ids)]\n",
    "    validate = df.loc[df['user_id'].isin(validate_ids)]\n",
    "    test = df.loc[df['user_id'].isin(test_ids)]\n",
    "\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = train_validate_test(acquire.get_riiid_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('mvp_50_train.csv', index=False)\n",
    "validate.to_csv('mvp_50_validate.csv', index=False)\n",
    "test.to_csv('mvp_50_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import acquire\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "import random\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four features I will explore:\n",
    "1. Running accuracy within a bundle\n",
    "2. Question Tag Accuracy\n",
    "3. Tag_#\n",
    "4. Cumulative user accuracy using Exponentially Weighted Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('sampled_trainset.csv')\n",
    "validate = pd.read_csv('validate.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove lectures rows from the training set.\n",
    "train = train.loc[(train.answered_correctly != -1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Analysis\n",
    "\n",
    "Part1<br>\n",
    "Photographs: 6 questions\n",
    ">Four short statements regarding a photograph will be spoken only one time. The statements will not be printed. Of these four statements, select the one that best describes the photograph and mark your answer on the answer sheet.\n",
    "\n",
    "Part2<br>\n",
    "Question-Response: 25 questions\n",
    ">Three responses to one question or statement will be spoken only one time. They will not be printed. Select the best response for the question, and mark your answer on the answer sheet.\n",
    "\n",
    "Part3<br>\n",
    "Conversations: 39 questions\n",
    ">Conversations between two or three people will be spoken only one time. They will not be printed. Listen to each conversation and read the questions printed in the test book (the questions will also be spoken), select the best response for the question, and mark your answer on the answer sheet. Some questions may require responses related to information found in diagrams,etc. printed on the test book as well as what you heard in the conversations. There are three questions for each conversation.\n",
    "\n",
    "Part4<br>\n",
    "Talks: 30 questions\n",
    ">Short talks such as announcements or narrations will be spoken only one time. They will not be printed. Listen to each talk and read the questions printed in the test book (the questions will also be spoken), select the best response for the question, and mark your answer on the answer sheet. Some questions may require responses related to information found in diagrams, etc. printed on the test book as well as what you heard in the talks. There are three questions for each talk.\n",
    "\n",
    "Reading Section (75 minutes, 100 questions): Read printed questions and answer them.<br>\n",
    "Part5<br>\n",
    "Incomplete Sentences: 30 questions\n",
    "> Select the best answer of the four choices to complete the sentence, and mark your answer on the answer sheet.\n",
    "\n",
    "Part6<br>\n",
    "Text Completion: 16 questions\n",
    ">Select the best answer of the four choices (words, phrases, or a sentence) to complete the text, and mark your answer on the answer sheet. There are four questions for each text.\n",
    "\n",
    "Part7<br>\n",
    "Single Passages: 29 questions\n",
    "Multiple Passages: 25 questions\n",
    "> A range of different texts will be printed in the test book. Read the questions, select the best answer of the four choices, and mark your answer on the answer sheet. Some questions may require you to select the best place to insert a sentence within a text. There are multiple questions for each text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "\n",
    "pd.crosstab(train.question_part, train.answered_correctly).plot.bar(figsize=(13, 7))\n",
    "\n",
    "plt.legend().set_visible(False)\n",
    "plt.title('How many user interactions are there for each part of the exam?')\n",
    "plt.xlabel('Part of Exam')\n",
    "plt.ylabel('Number of Questions (in Millions)')\n",
    "plt.xticks(np.arange(0, 7), labels=['1', '2', '3', '4', '5', '6', '7'], rotation=0)\n",
    "plt.yticks([1_000_000, 2_000_000, 3_000_000, 4_000_000, 5_000_000], labels=['1', '2', '3', '4', '5'], rotation=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "\n",
    "pd.crosstab(train.question_part, train.answered_correctly, normalize='index').plot.bar(figsize=(13, 7))\n",
    "plt.legend().set_visible(False)\n",
    "plt.title('How often do users get questions correct for each part of the exam?')\n",
    "plt.xlabel('Part of Exam')\n",
    "plt.ylabel('Percentage')\n",
    "plt.xticks(np.arange(0, 7), labels=['1', '2', '3', '4', '5', '6', '7'], rotation=0)\n",
    "plt.ylim(0, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponentially Weighted Mean of a users accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = train.loc[train.user_id == 24600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The culmulative total of questions answered correctly by a single user.\n",
    "user.answered_correctly.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of questions a single user has answered\n",
    "len(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user.answered_correctly.cumsum()/range(1, len(user.answered_correctly)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the cumulative accuracy of a single user\n",
    "plt.scatter(x=range(0, len(user.timestamp)),\n",
    "            y=user.answered_correctly.cumsum()\n",
    "              / range(1, len(user.answered_correctly)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user.answered_correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user.answered_correctly.ewm(3).mean().plot()\n",
    "user.answered_correctly.ewm(7).mean().plot()\n",
    "user.answered_correctly.ewm(10).mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "set_user = 0\n",
    "counter = 0\n",
    "\n",
    "for index, row in train[:5].iterrows():\n",
    "    user = row['user_id']\n",
    "    if set_user == 0:\n",
    "        current_user = row['user_id']\n",
    "        counter += 1\n",
    "    elif user != current_user:\n",
    "        counter = 0\n",
    "    elif user == current_user:\n",
    "        counter += 1\n",
    "        \n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "\n",
    "for id_ in train.user_id.unique()[:10]:\n",
    "    user_data = train['answered_correctly'].loc[train.user_id == id_]\n",
    "    id_num = train['user_id'].loc[train.user_id == id_]\n",
    "    user_ewm = pd.concat([id_num, user_data.ewm(3).mean()], axis=1)\n",
    "    data = pd.concat([data, user_ewm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.answered_correctly.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in data.user_id.unique():\n",
    "    data['answered_correctly'].loc[train.user_id == user].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check to see the number of unique values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in train.columns:\n",
    "    print(column, train[f'{column}'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bundle ID Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The accuracy of a user for each bundle they've taken.\n",
    "user.groupby(['bundle_id'])['answered_correctly'].mean().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby(['bundle_id'])['answered_correctly'].mean().iloc[:10].plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_accuracy = train.groupby(['bundle_id'])['answered_correctly'].mean().to_frame().reset_index()\n",
    "bundle_accuracy.columns = ['bundle_id', 'bundle_mean_accuracy']\n",
    "merged_train = train.merge(bundle_accuracy, left_on='bundle_id', right_on='bundle_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_accuracy = train.groupby(['question_part'])['answered_correctly'].agg(['mean']).reset_index()\n",
    "tag_accuracy.columns = ['question_part', 'part_accuracy']\n",
    "train_df = merged_train.merge(tag_accuracy, left_on='question_part', right_on='question_part')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Container Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_part_task_container = train.groupby(['question_part', 'task_container_id'])['answered_correctly'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_part_task_container.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_part_task_container.loc[mean_part_task_container.question_part == 2.0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of containers in part 1', len(mean_part_task_container.loc[mean_part_task_container.question_part == 1.0]))\n",
    "print('Number of containers in part 2', len(mean_part_task_container.loc[mean_part_task_container.question_part == 2.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_bundles = train.groupby(['question_id', 'task_container_id', 'question_part'])['answered_correctly'].mean().reset_index()\n",
    "tag_bundles.rename(columns={'answered_correctly': 'mean_container_part_accuracy'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_bundles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 7))\n",
    "for i in range(1, 8):\n",
    "    part_data = tag_bundles.loc[tag_bundles.question_part == float(i)]\n",
    "    sns.ecdfplot(data=part_data, x=\"mean_container_part_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.merge(tag_bundles, how='left', left_on='random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a function to reproduce feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_bundle_features(train, validate, test):\n",
    "    '''\n",
    "    This function accepts the train, validate, and test sets.\n",
    "    Returns new features on train, validate, and test using population stats from the training set.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Calculate the average accuracy for each unique bundle id\n",
    "    bundle_accuracy = train.groupby(['bundle_id'])['answered_correctly'].mean().to_frame().reset_index()\n",
    "    bundle_accuracy.columns = ['bundle_id', 'mean_bundle_accuracy']\n",
    "    \n",
    "    # Add bundle mean accuracy as a feature to train, validate, and test\n",
    "    merged_train = train.merge(bundle_accuracy, left_on='bundle_id', right_on='bundle_id', how='left')\n",
    "    merged_validate = validate.merge(bundle_accuracy, left_on='bundle_id', right_on='bundle_id', how='left')\n",
    "    merged_test = test.merge(bundle_accuracy, left_on='bundle_id', right_on='bundle_id', how='left')\n",
    "    \n",
    "    # Calculate the average part accuracy\n",
    "    tag_accuracy = train.groupby(['question_part'])['answered_correctly'].agg(['mean']).reset_index()\n",
    "    tag_accuracy.columns = ['question_part', 'mean_part_accuracy']\n",
    "    \n",
    "    # Add average part accuracy\n",
    "    train_df = merged_train.merge(tag_accuracy, left_on='question_part', right_on='question_part')\n",
    "    validate_df = merged_validate.merge(tag_accuracy, left_on='question_part', right_on='question_part')\n",
    "    test_df = merged_test.merge(tag_accuracy, left_on='question_part', right_on='question_part')\n",
    "    \n",
    "    # Calculate the mean container accuracy for each part\n",
    "    tag_bundles = train.groupby(['question_id', 'task_container_id', 'question_part'])['answered_correctly'].mean().reset_index()\n",
    "    tag_bundles.rename(columns={'answered_correctly': 'mean_container_part_accuracy'}, inplace=True)\n",
    "    \n",
    "    # Add mean container part accuracy\n",
    "    train_df = train_df.merge(tag_bundles)\n",
    "    validate_df = validate_df.merge(tag_bundles)\n",
    "    test_df = test_df.merge(tag_bundles)\n",
    "\n",
    "    \n",
    "    return train_df, validate_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = tag_bundle_features(train, validate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations between the features and the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.corr()['answered_correctly'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing\n",
    "---\n",
    "## Hypothesis Test\n",
    "### Question accuracy is dependent on the type of question asked.\n",
    "\n",
    "Test: Chi2 Test<br>\n",
    "$H_0$ Whether a user answers a question correctly is independent of the type of question being asked.<br>\n",
    "$H_a$ Whether a user answers a question correctly is dependent upon the type of question being asked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_interval = 0.95 \n",
    "alpha = 1 - alpha\n",
    "\n",
    "# Contingency table\n",
    "table = pd.crosstab(train_df.answered_correctly, train_df.question_part)\n",
    "chi2, p, dof, expected = stats.chi2_contingency(table)\n",
    "\n",
    "\n",
    "if p < alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (fail to reject H0)')\n",
    "    \n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- P is less than alpha so we <strong>reject</strong> the null hypothesis that answering a question correctly is independent of the type of question being asked. (Different parts of the TOEIC exam)\n",
    "\n",
    "- The 7 parts of the TOEIC exam require the user to answer questions with different formats: Pictures, Listening to conversations, Reading Conversations, Filling in Incomplete Sentences, etc. Depending on which part the user is answering questions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import acquire\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "import random\n",
    "random.seed(123)\n",
    "\n",
    "import prepare\n",
    "import explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('sampled_trainset.csv')\n",
    "validate = pd.read_csv('validate.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare.prep_riiid(train, validate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
