{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in primary dataset.\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training dataset\n",
    "To reduce the memory size of our training data, we selected a random sample of 100,000 students from `train.csv`.\n",
    "1. Select 100,000 user ids from `train.csv` to use as our train dataset.\n",
    "2. Cast numeric column data types using an appropriate precision to reduce memory size.\n",
    "\n",
    "## Sample training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random sample of 150_000 user ids.\n",
    "user_ids = df.user_id.sample(150_000, random_state=123)\n",
    "\n",
    "# Using the selected user_ids, filter the dataset for the first 100_000.\n",
    "filtered_data = pd.DataFrame()\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for user in user_ids:\n",
    "    \n",
    "    data = df.loc[df['user_id'] == user]\n",
    "    if data.shape[0] > 10 and counter < 100_000:\n",
    "        counter +=1\n",
    "        filtered_data = pd.concat([filtered_data, data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache local file for next steps.\n",
    "filtered_data.to_csv('filtered_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset loads correctly.\n",
    "df = pd.read_csv('filtered_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to reproduce the modified training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampled_train():\n",
    "    '''\n",
    "    This function selects a random sample of 100_000 users from the `train.csv` dataset.\n",
    "    Returns a dataframe of 100_000 users that have more than 10 rows of data.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    None\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    prepared_train : pandas.core.frame.DataFrame\n",
    "        A pandas dataframe of 100,000 randomly selected\n",
    "        users.\n",
    "    '''\n",
    "    \n",
    "    train_data_types_dict = {\n",
    "        'timestamp': np.int64,\n",
    "        'user_id': np.int32,\n",
    "        'content_id': np.int16,\n",
    "        'content_type_id': np.int16,\n",
    "        'task_container_id' : np.int16,\n",
    "        'user_answer' : np.int8,\n",
    "        'answered_correctly': np.int8,\n",
    "        'prior_question_elapsed_time': np.float16\n",
    "    }\n",
    "    \n",
    "    # Read in `train.csv` data\n",
    "    df = pd.read_csv('train.csv', dtype=train_data_types_dict)\n",
    "\n",
    "    # Generate a random sample of 150_000 user ids.\n",
    "    user_ids = df.user_id.sample(150_000, random_state=123)\n",
    "\n",
    "    # Using the selected user_ids, filter the dataset for the first 100_000.\n",
    "    filtered_data = pd.DataFrame()\n",
    "\n",
    "    # Create a counter to stop at 100_000.\n",
    "    counter = 0\n",
    "\n",
    "    for user in user_ids:\n",
    "        data = df.loc[df['user_id'] == user]\n",
    "        if data.shape[0] > 10 and counter < 100_000:\n",
    "            counter +=1\n",
    "            filtered_data = pd.concat([filtered_data, data])\n",
    "    \n",
    "    # Drop the index of filtered users.\n",
    "    filtered_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Cache local file of sampled data.\n",
    "    filtered_data.to_csv('filtered_train.csv', index=False)\n",
    "    \n",
    "    # Return the dataframe\n",
    "    return prepared_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5fc62866a8e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampled_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-50b7e53ab18a>\u001b[0m in \u001b[0;36msampled_train\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m100_000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mfiltered_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfiltered_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# Drop the index of filtered users.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             new_data = concatenate_block_managers(\n\u001b[0;32m--> 503\u001b[0;31m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbm_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             )\n\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_extension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;31m# TODO(EA2D): special-casing not needed with 2D EAs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/concat.py\u001b[0m in \u001b[0;36mconcat_compat\u001b[0;34m(to_concat, axis)\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0mto_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"object\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test the function.\n",
    "df = sampled_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It works.\n",
    "df.user_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check our data types and memory usage.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datatype_converter(file_name='train'):\n",
    "    '''\n",
    "    This function accepts a csv file name.\n",
    "    Returns a dictionary of column names and data types.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name : str, optional, default='train'\n",
    "        Acceptable file names\n",
    "        - 'lectures'\n",
    "            refers to columns in `lectures.csv`\n",
    "        - 'train'\n",
    "        - 'questions'\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    train_data_types_dict = {\n",
    "    'timestamp': np.int64,\n",
    "    'user_id': np.int32,\n",
    "    'content_id': np.int16,\n",
    "    'content_type_id': np.int16,\n",
    "    'task_container_id' : np.int16,\n",
    "    'user_answer' : np.int8,\n",
    "    'answered_correctly': np.int8,\n",
    "    'prior_question_elapsed_time': np.float16\n",
    "    }\n",
    "    \n",
    "    return train_data_types_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_id in user_ids1000:\n",
    "    if train1000.loc[[user_id]].shape[0] <=10:\n",
    "        print(user_id)\n",
    "        continue\n",
    "    elif train1000.loc[[user_id]].shape[0] > 2: \n",
    "        df = train1000.loc[[user_id]]\n",
    "        n = df.shape[0]\n",
    "        test_start_index = round(train_size * n)\n",
    "        df_train = df.iloc[:test_start_index]\n",
    "        df_test = df.iloc[test_start_index:]     \n",
    "        train = pd.concat([train, df_train])\n",
    "        test = pd.concat([test, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = df.user_id.unique()\n",
    "\n",
    "train = pd.DataFrame()\n",
    "validate = pd.DataFrame()\n",
    "test = pd.DataFrame()\n",
    "\n",
    "# Set up the train size\n",
    "train_size = 0.8\n",
    "validate_size = 0.1\n",
    "    \n",
    "train_end_index = int(train_size * n)\n",
    "validate_end_index = train_end_index + int(validate_size * n)\n",
    "\n",
    "df_train = df.iloc[:train_end_index]\n",
    "df_validate = df.iloc[train_end_index:validate_end_index]\n",
    "df_test = df.iloc[validate_end_index:]\n",
    "\n",
    "train = pd.concat([train, df_train])\n",
    "validate = pd.concat([validate, df_validate])\n",
    "test = pd.concat([test, df_test])\n",
    "\n",
    "# Print the shape of the original, train and test\n",
    "df_train.shape, train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = acquire.get_riiid_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
