{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import acquire\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "import random\n",
    "random.seed(123)\n",
    "\n",
    "import prepare\n",
    "import explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquire the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in primary dataset.\n",
    "df = pd.read_csv('train.csv', usecols=[1,2,3,4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training dataset\n",
    "To reduce the memory size of our training data, we selected a random sample of 100,000 students from `train.csv`.\n",
    "1. Select 100,000 user ids from `train.csv` to use as our train dataset.\n",
    "2. Cast numeric column data types using an appropriate precision to reduce memory size.\n",
    "\n",
    "### Sample training data\n",
    "- Selecting 100_000 users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all users with more than 10 rows.\n",
    "user_ids = df['user_id'].value_counts()[df['user_id'].value_counts() > 10].index.to_list()\n",
    "\n",
    "# Select a random sample of 100_000 user_ids.\n",
    "sampled_ids = random.sample(user_ids, 100_000)\n",
    "len(sampled_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampled_users(df):\n",
    "    '''\n",
    "    This function accepts data from `train.csv` and\n",
    "    returns a random sample of 100_000 user_ids.\n",
    "    '''\n",
    "    user_ids = df['user_id'].value_counts()[df['user_id'].value_counts() > 10].index.to_list()\n",
    "    sampled_ids = random.sample(user_ids, 100_000)\n",
    "    return sampled_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.loc[df['user_id'].isin(sampled_ids)]\n",
    "\n",
    "# We have 100_000 users!!!!\n",
    "data.user_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casting data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datatype_converter():\n",
    "    '''\n",
    "    This function returns a dictionary of column names and data types to convert.\n",
    "    '''\n",
    "    \n",
    "    train_data_types_dict = {\n",
    "    'timestamp': np.int64,\n",
    "    'user_id': np.int32,\n",
    "    'content_id': np.int16,\n",
    "    'content_type_id': np.int16,\n",
    "    'task_container_id' : np.int16,\n",
    "    'user_answer' : np.int8,\n",
    "    'answered_correctly': np.int8,\n",
    "    'prior_question_elapsed_time': np.float16\n",
    "    }\n",
    "    \n",
    "    lectures_data_types_dict = {\n",
    "    'lecture_id' : np.int16,\n",
    "    'tag' : np.int8,\n",
    "    'part' : np.int8\n",
    "    }\n",
    "\n",
    "    questions_data_types_dict = {\n",
    "    'question_id' : np.int16,\n",
    "    'bundle_id' : np.int16,\n",
    "    'part' : np.int8\n",
    "    }\n",
    "    \n",
    "    \n",
    "    return train_data_types_dict, lectures_data_types_dict, questions_data_types_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to reproduce the modified training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampled_train():\n",
    "    '''\n",
    "    This function selects a random sample of 100_000 users from the `train.csv` dataset.\n",
    "    Returns a dataframe of 100_000 users that have more than 10 rows of data.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    None\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data : pandas.core.frame.DataFrame\n",
    "        A pandas dataframe of 100,000 randomly selected\n",
    "        users.\n",
    "    '''\n",
    "    train_dtypes, _, _ = datatype_converter()\n",
    "    \n",
    "    if os.path.isfile('sampled_train.csv'):\n",
    "        return pd.read_csv('sampled_train.csv',\n",
    "                           index_col=False,\n",
    "                           dtype=train_dtypes)\n",
    "    else:\n",
    "        \n",
    "    # Read in `train.csv` data\n",
    "        df = pd.read_csv('train.csv', dtype=train_dtypes, usecols=[1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "        sampled_ids = sampled_users(df)\n",
    "\n",
    "        sampled_data = df.loc[df['user_id'].isin(sampled_ids)]\n",
    "\n",
    "        # Cache local file of sampled data.\n",
    "        sampled_data.to_csv('sampled_train.csv', index=False)\n",
    "    \n",
    "    # Return the dataframe\n",
    "    return sampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25745784 entries, 46 to 101229974\n",
      "Data columns (total 9 columns):\n",
      " #   Column                          Dtype  \n",
      "---  ------                          -----  \n",
      " 0   timestamp                       int64  \n",
      " 1   user_id                         int32  \n",
      " 2   content_id                      int16  \n",
      " 3   content_type_id                 int16  \n",
      " 4   task_container_id               int16  \n",
      " 5   user_answer                     int8   \n",
      " 6   answered_correctly              int8   \n",
      " 7   prior_question_elapsed_time     float16\n",
      " 8   prior_question_had_explanation  object \n",
      "dtypes: float16(1), int16(3), int32(1), int64(1), int8(2), object(1)\n",
      "memory usage: 933.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Test the function.\n",
    "df_train = sampled_train()\n",
    "# It works.\n",
    "df_train.user_id.value_counts()\n",
    "\n",
    "# Check our data types and memory usage.\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge datasets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25745784 entries, 0 to 25745783\n",
      "Data columns (total 18 columns):\n",
      " #   Column                          Dtype  \n",
      "---  ------                          -----  \n",
      " 0   timestamp                       int64  \n",
      " 1   user_id                         int32  \n",
      " 2   content_id                      int16  \n",
      " 3   content_type_id                 int16  \n",
      " 4   task_container_id               int16  \n",
      " 5   user_answer                     int8   \n",
      " 6   answered_correctly              int8   \n",
      " 7   prior_question_elapsed_time     float16\n",
      " 8   prior_question_had_explanation  object \n",
      " 9   lecture_id                      float64\n",
      " 10  tag                             float64\n",
      " 11  part_x                          float64\n",
      " 12  type_of                         object \n",
      " 13  question_id                     float64\n",
      " 14  bundle_id                       float64\n",
      " 15  correct_answer                  float64\n",
      " 16  part_y                          float64\n",
      " 17  tags                            object \n",
      "dtypes: float16(1), float64(7), int16(3), int32(1), int64(1), int8(2), object(3)\n",
      "memory usage: 2.6+ GB\n"
     ]
    }
   ],
   "source": [
    "_, lecture_dtypes, question_dtypes = datatype_converter()\n",
    "\n",
    "df_lectures = pd.read_csv('lectures.csv', dtype=lecture_dtypes)\n",
    "df_questions = pd.read_csv('questions.csv', dtype=question_dtypes)\n",
    "\n",
    "# Left join df_train and df_lectures using `content_id` as the primary key.\n",
    "df_merged = df_train.merge(df_lectures, left_on='content_id', right_on='lecture_id', how='left')\n",
    "\n",
    "# Left join df_merged and df_questions using `content_id` as the primary key.\n",
    "df_data = df_merged.merge(df_questions, left_on='content_id', right_on='question_id', how='left')\n",
    "\n",
    "df_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>user_answer</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "      <th>lecture_id</th>\n",
       "      <th>tag</th>\n",
       "      <th>lecture_part</th>\n",
       "      <th>type_of</th>\n",
       "      <th>question_id</th>\n",
       "      <th>bundle_id</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>question_part</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>5692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5692</td>\n",
       "      <td>5692</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56943</td>\n",
       "      <td>115</td>\n",
       "      <td>5716</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>36992.0</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5716</td>\n",
       "      <td>5716</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118363</td>\n",
       "      <td>115</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55008.0</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>131 149 92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131167</td>\n",
       "      <td>115</td>\n",
       "      <td>7860</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19008.0</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7860</td>\n",
       "      <td>7860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>131 104 81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137965</td>\n",
       "      <td>115</td>\n",
       "      <td>7922</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7922</td>\n",
       "      <td>7922</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>131 149 92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  user_id  content_id  content_type_id  task_container_id  \\\n",
       "0          0      115        5692                0                  1   \n",
       "1      56943      115        5716                0                  2   \n",
       "2     118363      115         128                0                  0   \n",
       "3     131167      115        7860                0                  3   \n",
       "4     137965      115        7922                0                  4   \n",
       "\n",
       "   user_answer  answered_correctly  prior_question_elapsed_time  \\\n",
       "0            3                   1                          NaN   \n",
       "1            2                   1                      36992.0   \n",
       "2            0                   1                      55008.0   \n",
       "3            0                   1                      19008.0   \n",
       "4            1                   1                      11000.0   \n",
       "\n",
       "  prior_question_had_explanation  lecture_id   tag  lecture_part type_of  \\\n",
       "0                            NaN        <NA>  <NA>          <NA>     NaN   \n",
       "1                          False        <NA>  <NA>          <NA>     NaN   \n",
       "2                          False        <NA>  <NA>          <NA>     NaN   \n",
       "3                          False        <NA>  <NA>          <NA>     NaN   \n",
       "4                          False        <NA>  <NA>          <NA>     NaN   \n",
       "\n",
       "   question_id  bundle_id  correct_answer  question_part        tags  \n",
       "0         5692       5692             3.0              5         151  \n",
       "1         5716       5716             2.0              5         168  \n",
       "2          128        128             0.0              1  131 149 92  \n",
       "3         7860       7860             0.0              1  131 104 81  \n",
       "4         7922       7922             1.0              1  131 149 92  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing if the function works.\n",
    "import acquire\n",
    "\n",
    "df = acquire.get_riiid_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train, validate, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame()\n",
    "validate = pd.DataFrame()\n",
    "test = pd.DataFrame()\n",
    "\n",
    "# Set up the train size\n",
    "train_size = 0.8\n",
    "validate_size = 0.1\n",
    "\n",
    "sampled_ids = df.user_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in sampled_ids:\n",
    "    data = df.loc[df['user_id'] == user]\n",
    "    n = data.shape[0]\n",
    "\n",
    "    train_end_index = int(train_size * n)\n",
    "    validate_end_index = train_end_index + int(validate_size * n)\n",
    "\n",
    "    df_train = data.iloc[:train_end_index]\n",
    "    df_validate = data.iloc[train_end_index:validate_end_index]\n",
    "    df_test = data.iloc[validate_end_index:]\n",
    "\n",
    "    train = pd.concat([train, df_train])\n",
    "    validate = pd.concat([validate, df_validate])\n",
    "    test = pd.concat([test, df_test]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.to_csv('sampled_trainset.csv', index=False)\n",
    "validate.to_csv('validate.csv', index=False)\n",
    "test.to_csv('test.csv', index=False)\n",
    "\n",
    "type(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four features I will explore:\n",
    "1. Running accuracy within a bundle\n",
    "2. Question Tag Accuracy\n",
    "3. Tag_#\n",
    "4. Cumulative user accuracy using Exponentially Weighted Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>question_had_explanation</th>\n",
       "      <th>user_acc_mean</th>\n",
       "      <th>user_lectures_running_total</th>\n",
       "      <th>q_time</th>\n",
       "      <th>avg_user_q_time</th>\n",
       "      <th>...</th>\n",
       "      <th>bundle_id</th>\n",
       "      <th>part</th>\n",
       "      <th>tags</th>\n",
       "      <th>tag_count</th>\n",
       "      <th>mean_bundle_accuracy</th>\n",
       "      <th>mean_part_accuracy</th>\n",
       "      <th>mean_content_accuracy</th>\n",
       "      <th>mean_task_accuracy</th>\n",
       "      <th>mean_tagcount_accuracy</th>\n",
       "      <th>mean_tags_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>24600</td>\n",
       "      <td>7900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0</td>\n",
       "      <td>25379.0</td>\n",
       "      <td>70525.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7900</td>\n",
       "      <td>1</td>\n",
       "      <td>131 93 81</td>\n",
       "      <td>3</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25379</td>\n",
       "      <td>24600</td>\n",
       "      <td>7876</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0</td>\n",
       "      <td>24758.0</td>\n",
       "      <td>70525.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7876</td>\n",
       "      <td>1</td>\n",
       "      <td>10 94 92</td>\n",
       "      <td>3</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50137</td>\n",
       "      <td>24600</td>\n",
       "      <td>175</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0</td>\n",
       "      <td>20044.0</td>\n",
       "      <td>70525.0</td>\n",
       "      <td>...</td>\n",
       "      <td>175</td>\n",
       "      <td>1</td>\n",
       "      <td>9 10 92</td>\n",
       "      <td>3</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>128919</td>\n",
       "      <td>7900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>22862.0</td>\n",
       "      <td>60393.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7900</td>\n",
       "      <td>1</td>\n",
       "      <td>131 93 81</td>\n",
       "      <td>3</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22862</td>\n",
       "      <td>128919</td>\n",
       "      <td>7876</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>24620.0</td>\n",
       "      <td>60393.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7876</td>\n",
       "      <td>1</td>\n",
       "      <td>10 94 92</td>\n",
       "      <td>3</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  user_id  content_id  task_container_id  answered_correctly  \\\n",
       "0          0    24600        7900                  0                   1   \n",
       "1      25379    24600        7876                  1                   0   \n",
       "2      50137    24600         175                  2                   1   \n",
       "3          0   128919        7900                  0                   1   \n",
       "4      22862   128919        7876                  1                   0   \n",
       "\n",
       "  question_had_explanation  user_acc_mean  user_lectures_running_total  \\\n",
       "0                    False       0.275000                            0   \n",
       "1                    False       0.275000                            0   \n",
       "2                    False       0.275000                            0   \n",
       "3                    False       0.333333                            0   \n",
       "4                    False       0.333333                            0   \n",
       "\n",
       "    q_time  avg_user_q_time  ...  bundle_id  part       tags tag_count  \\\n",
       "0  25379.0          70525.0  ...       7900     1  131 93 81         3   \n",
       "1  24758.0          70525.0  ...       7876     1   10 94 92         3   \n",
       "2  20044.0          70525.0  ...        175     1    9 10 92         3   \n",
       "3  22862.0          60393.0  ...       7900     1  131 93 81         3   \n",
       "4  24620.0          60393.0  ...       7876     1   10 94 92         3   \n",
       "\n",
       "   mean_bundle_accuracy  mean_part_accuracy  mean_content_accuracy  \\\n",
       "0                  0.82                0.74                   0.82   \n",
       "1                  0.41                0.74                   0.41   \n",
       "2                  0.36                0.74                   0.36   \n",
       "3                  0.82                0.74                   0.82   \n",
       "4                  0.41                0.74                   0.41   \n",
       "\n",
       "   mean_task_accuracy  mean_tagcount_accuracy  mean_tags_accuracy  \n",
       "0                0.68                    0.68                0.78  \n",
       "1                0.53                    0.68                0.49  \n",
       "2                0.44                    0.68                0.52  \n",
       "3                0.68                    0.68                0.78  \n",
       "4                0.53                    0.68                0.49  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('sampled_trainset.csv')\n",
    "validate = pd.read_csv('validate.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train, validate, test, train_s, validate_s, test_s = prepare.prep_riiid(train, validate, test)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations between the features and the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "answered_correctly             1.000000\n",
       "mean_content_accuracy          0.371355\n",
       "mean_bundle_accuracy           0.326742\n",
       "user_acc_mean                  0.234599\n",
       "mean_tags_accuracy             0.225834\n",
       "mean_task_accuracy             0.136495\n",
       "mean_part_accuracy             0.101206\n",
       "mean_tagcount_accuracy         0.085828\n",
       "tag_count                      0.083321\n",
       "task_container_id              0.056813\n",
       "user_lectures_running_total    0.032799\n",
       "timestamp                      0.026536\n",
       "user_id                       -0.000344\n",
       "q_time                        -0.011355\n",
       "content_id                    -0.020392\n",
       "question_id                   -0.020392\n",
       "bundle_id                     -0.020394\n",
       "avg_user_q_time               -0.022674\n",
       "part                          -0.072469\n",
       "Name: answered_correctly, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.corr()['answered_correctly'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `bundle_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8b36f85ad0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_context('talk')\n",
    "\n",
    "sns.histplot(data=train, x='mean_bundle_accuracy', bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing\n",
    "---\n",
    "## Hypothesis Test\n",
    "### Question accuracy is dependent on the type of question asked.\n",
    "\n",
    "Test: Chi2 Test<br>\n",
    "$H_0$ Whether a user answers a question correctly is independent of the type of question being asked.<br>\n",
    "$H_a$ Whether a user answers a question correctly is dependent upon the type of question being asked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependent (reject H0)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "confidence_interval = 0.95 \n",
    "alpha = 1 - confidence_interval\n",
    "\n",
    "# Contingency table\n",
    "table = pd.crosstab(train.answered_correctly, train.part)\n",
    "chi2, p, dof, expected = stats.chi2_contingency(table)\n",
    "\n",
    "\n",
    "if p < alpha:\n",
    "    print('Dependent (reject H0)')\n",
    "else:\n",
    "    print('Independent (fail to reject H0)')\n",
    "    \n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- P is less than alpha so we <strong>reject</strong> the null hypothesis that answering a question correctly is independent of the type of question being asked. (Different parts of the TOEIC exam)\n",
    "\n",
    "- The 7 parts of the TOEIC exam require the user to answer questions with different formats: Pictures, Listening to conversations, Reading Conversations, Filling in Incomplete Sentences, etc. Depending on which part the user is answering questions..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train, validate, and test into X_set and y_sets\n",
    "X_train = train_s[['user_acc_mean', 'mean_content_accuracy']].copy()\n",
    "y_train = train_s['answered_correctly'].copy()\n",
    "\n",
    "X_validate = validate_s[['user_acc_mean', 'mean_content_accuracy']].copy()\n",
    "y_validate = validate_s['answered_correctly'].copy()\n",
    "\n",
    "X_test = test_s[['user_acc_mean', 'mean_content_accuracy']].copy()\n",
    "y_test = test_s['answered_correctly'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently running on model Linear SVM\n"
     ]
    }
   ],
   "source": [
    "names = [\"Linear SVM\"]\n",
    "\n",
    "\n",
    "classifiers = [\n",
    "    SVC()]\n",
    "\n",
    "param_grid = [{'gamma': [0.001, 0.01, 0.1],\n",
    "               'C': [0.001, 0.01, 0.1]}]\n",
    "\n",
    "# iterate over classifiers\n",
    "for name, clf, param_grid in zip(names, classifiers, param_grid):\n",
    "\n",
    "    # Set up a progress indicator        \n",
    "    print(f\"Currently running on model {name}\") \n",
    "\n",
    "    # Fit on the train dataset        \n",
    "    clf = GridSearchCV(clf, param_grid=param_grid, cv=5, scoring='roc_auc')\n",
    "    clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=[0])\n",
    "validate_data = lgb.Dataset(X_validate, label=y_validate)\n",
    "\n",
    "parameters = {\n",
    "    'application': 'binary',\n",
    "    'metric': 'auc'\n",
    "}\n",
    "\n",
    "# Predict on validate\n",
    "model = lgb.train(parameters,\n",
    "                  train_data,\n",
    "                  valid_sets=validate_data,\n",
    "                  verbose_eval=100,\n",
    "                  num_boost_round=10000,\n",
    "                  early_stopping_rounds=10)\n",
    "\n",
    "y_pred = model.predict(X_validate)\n",
    "\n",
    "lgb.plot_importance(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `mean_container_part_accuracy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating the usefulness of `mean_container_part_accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users_per_container = train.groupby(['part',\n",
    "                                            'task_container_id',\n",
    "                                            'bundle_id'])\\\n",
    "                            .user_id\\\n",
    "                            .nunique()\\\n",
    "                            .reset_index()\n",
    "\n",
    "unique_users_per_container['mean_container_part_accuracy'] = train.groupby(['part',\n",
    "                                                                            'task_container_id',\n",
    "                                                                            'bundle_id'])\\\n",
    "                                                            .answered_correctly\\\n",
    "                                                            .mean().reset_index(drop=True)\n",
    "\n",
    "part_mean_accuracy = train.groupby('part').answered_correctly.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_data = unique_users_per_container.merge(part_mean_accuracy, on='part')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 million questions answered by a single user.\n",
    "one_user = (container_data.user_id == 1).sum()\n",
    "print(one_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 million questions answered by two users.\n",
    "two_users = (container_data.user_id == 2).sum()\n",
    "print(two_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 500k questions answered by three users.\n",
    "three_users = (container_data.user_id == 3).sum()\n",
    "print(three_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = (one_user + two_users + three_users).sum()\n",
    "\n",
    "print(f'{total:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{total/train.shape[0]:0.0%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "plt.figure(figsize=(13, 7))\n",
    "\n",
    "sns.histplot(data=train,\n",
    "             x='mean_container_part_accuracy',\n",
    "             hue='is_reading',\n",
    "             palette='Set1',\n",
    "             bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby(by=['task_container_id', 'bundle_id', 'part'])['answered_correctly']\\\n",
    "            .agg(['count', 'mean'])\\\n",
    "            .reset_index()\\\n",
    "            .sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "\n",
    "sns.relplot(data=train.sample(1000),\n",
    "            x=\"mean_container_part_accuracy\",\n",
    "            y=\"user_acc_mean\",\n",
    "            col=\"part\",\n",
    "            col_wrap=4,\n",
    "            hue=\"answered_correctly\",\n",
    "            style=\"answered_correctly\",\n",
    "            kind=\"scatter\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=train.sample(1000),\n",
    "              x=\"mean_container_part_accuracy\",\n",
    "              y=\"user_acc_mean\",\n",
    "              col='part',\n",
    "              col_wrap=4,\n",
    "              hue=\"answered_correctly\",\n",
    "              kind=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for id_ in train.user_id.unique()[10:15]:\n",
    "    user_data = train['answered_correctly'].loc[train.user_id == id_]\n",
    "    id_num = train['user_id'].loc[train.user_id == id_]\n",
    "    user_ewm = pd.concat([id_num, user_data.ewm(3).mean()], axis=1)\n",
    "    data = pd.concat([data, user_ewm])\n",
    "\n",
    "for user in data.user_id.unique():\n",
    "    data['answered_correctly'].loc[train.user_id == user].plot()\n",
    "\n",
    "user = train.loc[train.user_id == 24600]\n",
    "\n",
    "user.head()\n",
    "\n",
    "# The culmulative total of questions answered correctly by a single user.\n",
    "user.answered_correctly.cumsum()\n",
    "\n",
    "# Number of questions a single user has answered\n",
    "len(user)\n",
    "\n",
    "user.answered_correctly.cumsum()/range(1, len(user.answered_correctly)+1)\n",
    "\n",
    "# Calculating the cumulative accuracy of a single user\n",
    "plt.scatter(x=range(0, len(user.timestamp)),\n",
    "            y=user.answered_correctly.cumsum()\n",
    "              / range(1, len(user.answered_correctly)+1))\n",
    "\n",
    "user.answered_correctly\n",
    "\n",
    "user.answered_correctly.ewm(3).mean().plot()\n",
    "user.answered_correctly.ewm(7).mean().plot()\n",
    "user.answered_correctly.ewm(10).mean().plot()\n",
    "\n",
    "set_user = 0\n",
    "counter = 0\n",
    "\n",
    "for index, row in train[:5].iterrows():\n",
    "    user = row['user_id']\n",
    "    if set_user == 0:\n",
    "        current_user = row['user_id']\n",
    "        counter += 1\n",
    "    elif user != current_user:\n",
    "        counter = 0\n",
    "    elif user == current_user:\n",
    "        counter += 1\n",
    "        \n",
    "print(counter)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_users(df, train_size=.8, validate_size=.1, test_size=.1, sample=True, n=100_000):\n",
    "    '''\n",
    "    This function accepts the merged dataframe from acquire.get_riiid_data()\n",
    "    and returns train, validate and test sets.\n",
    "    '''\n",
    "    # Set a random seed to reproduce splits\n",
    "    random.seed(123)\n",
    "    \n",
    "    if sample == True:\n",
    "        # Gather a random sample of 100_000 user ids\n",
    "        user_ids = random.sample(list(df['user_id'].unique()), n)\n",
    "    else:\n",
    "        # Gather all user ids\n",
    "        user_ids = list(df['user_id'].unique())\n",
    "    \n",
    "    # Calculate the number of users\n",
    "    total_num = len(user_ids)\n",
    "    \n",
    "    # Calculate the number of users in train, validate. Remaining users go in test\n",
    "    train_num = int(total_num*train_size)\n",
    "    validate_num = math.ceil(total_num*validate_size)\n",
    "    \n",
    "    # Randomly select 80% of the users to be in train.\n",
    "    train_ids = random.sample(user_ids, train_num)\n",
    "    \n",
    "    # Remove user_ids assigned to the training set.\n",
    "    remaining_val_test_users = list(set(user_ids) - set(train_ids))\n",
    "    \n",
    "    # Assign the remaining user ids to validate and test.\n",
    "    validate_ids = random.sample(remaining_val_test_users, validate_num)\n",
    "    test_ids = list(set(remaining_val_test_users) - set(validate_ids))\n",
    "    \n",
    "    # Return the users assigned to train, validate, and test\n",
    "    return train_ids, validate_ids, test_ids\n",
    "\n",
    "\n",
    "def train_validate_test(df, sampled=True):\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    train_ids, validate_ids, test_ids = split_users(df, sample=sampled)\n",
    "\n",
    "    train = df.loc[df['user_id'].isin(train_ids)]\n",
    "    validate = df.loc[df['user_id'].isin(validate_ids)]\n",
    "    test = df.loc[df['user_id'].isin(test_ids)]\n",
    "\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = train_validate_test(acquire.get_riiid_data())\n",
    "\n",
    "train.to_csv('sampled_train.csv', index=False)\n",
    "validate.to_csv('sampled_validate.csv', index=False)\n",
    "test.to_csv('sampled_test.csv', index=False)\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a function to split data using Quasi-GroupKFold method\n",
    "The way our data is currently split for MVP:\n",
    "- 100,000 randomly selected users that have more that 10 interactions with Riiid's Knowledge tracing application.\n",
    "- Each user has _sequential_ data, indicated by the variable `timestamp`.\n",
    "- Data is split using a percentage-based method.\n",
    "- 0% - 80% of a users data is the training set.\n",
    "- 80% - 90% of a users data is in the validation set.\n",
    "- 90% - 100% of a users data is in the test set.\n",
    "\n",
    "The way we split the data is important. As we currently have our splits, several issues arise that impact our data exploration and modeling performance.\n",
    "- Spliting the data using a percentage-based method removes questions and lectures from our training data. If a model encounters a question it has never seen before, how can it accurately model reality? We need to have all questions appear at least once in our dataset.\n",
    "    - If this was _purely_ a time series problem, that would be fine.\n",
    "- The training set uses 80% of a users data, this impacts our statistical analysis. If we have _all_ of a users data, we can correctly calculate population statistics from a _sample_ of users. We can then compare statistics on a user/grouped level with the population.\n",
    "\n",
    "What is the solution?\n",
    "\n",
    "> <strong>Splitting by users!</strong>\n",
    "\n",
    "## Splitting by users\n",
    "How does this solve our exploration and modeling issues?\n",
    "> <strong>By creating users the model has never seen before!</strong>\n",
    "\n",
    "This simulates _new_ users interacting with Riiid's Knowledge Tracing Application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for even splits\n",
    "print(len(users) == sum([train_users, validate_users, test_users]))\n",
    "\n",
    "print(len(users))\n",
    "print(sum([train_users, validate_users, test_users]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test a method to split users into seperate datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function to reproduce data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_users(df, train_size=.8, validate_size=.1, test_size=.1):\n",
    "    '''\n",
    "    This function accepts the merged dataframe from acquire.get_riiid_data()\n",
    "    and returns train, validate and test sets.\n",
    "    '''\n",
    "    # Set a random seed to reproduce splits\n",
    "    random.seed(123)\n",
    "    \n",
    "    # Gather all user ids\n",
    "    user_ids = list(df['user_id'].unique())\n",
    "    total_num = len(user_ids)\n",
    "    \n",
    "    # Calculate the number of users in train, validate, and test.\n",
    "    train_num = int(total_num*train_size)\n",
    "    validate_num = math.ceil(total_num*validate_size)\n",
    "    test_num = math.ceil(total_num*test_size)\n",
    "    \n",
    "    # Randomly select 80% of the users to be in train.\n",
    "    train_ids = random.sample(user_ids, train_num)\n",
    "    \n",
    "    # Remove user_ids assigned to the training set.\n",
    "    remaining_val_test_users = list(set(user_ids) - set(train_ids))\n",
    "    \n",
    "    # Assign the remaining user ids to validate and test.\n",
    "    validate_ids = random.sample(remaining_val_test_users, validate_num)\n",
    "    test_ids = list(set(remaining_val_test_users) - set(validate_ids))\n",
    "    \n",
    "    # Return the users assigned to train, validate, and test\n",
    "    return train_ids, validate_ids, test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_ids, validate_ids, test_ids = split_users(df_data)\n",
    "\n",
    "# Filter user ids into train, validate, and test dataframes.\n",
    "train = df_data.loc[df_data['user_id'].isin(train_ids)]\n",
    "validate = df_data.loc[df_data['user_id'].isin(validate_ids)]\n",
    "test = df_data.loc[df_data['user_id'].isin(test_ids)]\n",
    "\n",
    "# Save these files as _kfold to distinguish as GroupKFold Split data.\n",
    "train.to_csv('train_kfold.csv', index=False)\n",
    "validate.to_csv('validate_kfold.csv', index=False)\n",
    "test.to_csv('test_kfold.csv', index=False)\n",
    "\n",
    "train.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
